# Pricing Intel

Turn market signals into **smarter nightly rates**.
Pricing Intel ingests market samples, occupancy and event signals to generate **price recommendations with confidence bands** ‚Äî live, on demand.

## ‚ú® Features

* **Dashboard**: listings overview, city/room stats, API health.
* **Listing detail**: interactive date-range picker (deferred fetch + loading state), confidence band chart, quick KPIs.
* **Compare**: overlay up to 5 listings on one chart **and** show per-listing mini charts.
* **On-demand predictions**: compute & return recommendations for any custom date range.
* **Rolling precompute**: daily task stores the next 30 days of recs so the UI is fast by default.
* **(Optional) LLM explanations**: generate human-friendly copy describing why a price is recommended.

## üèóÔ∏è Architecture

```
frontend/         Vite + React + TypeScript + Tailwind UI
backend/
  apps/
    listings/     Listing + MarketSample + FeaturesDaily models & API
    recommendations/
                   Recommendation model, sync/async tasks, API
    llmcore/      Optional: thin client + /api/llm/quote endpoint
  config/         Django settings, URLs, Celery app
```

### Data flow (high level)

1. **Market data** (`MarketSample`) + **daily features** (`FeaturesDaily`) exist per city/date.
2. When a user opens a listing:

   * By default, the UI loads the precomputed window (e.g., next 14 days).
   * If the user selects custom dates and clicks **Get live recommendation**, the UI calls
     `GET /api/listings/:id/recommendations/?from=YYYY-MM-DD&to=YYYY-MM-DD`.
3. The API **synchronously** generates any missing days for **that listing and window only** and then returns the full range.
4. Charts render **confidence band** (¬±10%) around the recommended price.

## ‚öôÔ∏è Tech stack

* **Frontend**: React 18, TypeScript, Vite, TailwindCSS (with small animation utilities).
* **Backend**: Django 5, Django REST Framework, Celery.
* **Task queue**: Celery (broker: Redis or RabbitMQ ‚Äî choose via env).
* **DB**: Any Django-supported DB (SQLite for local dev; Postgres recommended in prod).
* **Containerization**: Docker + Compose (optional).

## üß† Pricing logic (baseline)

For each date *d*:

* Inputs:

  * `ms_price` ‚Äì market sample price for the city/date
  * `rooms` ‚Äì listing rooms
  * `occ` ‚Äì occupancy %
  * `event_score` ‚Äì simple [0..] score for events
  * `dow` ‚Äì day of week
* Formula (simplified):

```py
base = ms_price * (1 + 0.08 * max(0, rooms - 1))     # rooms lift
base *= (1 + (occ - 65) / 300.0)                      # occupancy adjustment
if dow in (4, 5):                                     # Fri/Sat
    base *= 1.10
base *= (1 + event_score / 50.0)                      # event lift
price = clamp(base, min=1000, max=ms_price*2)         # guardrails
conf_low  = price * 0.90
conf_high = price * 1.10
```

You can swap this baseline with a more advanced model later; the API surface remains the same.

## üí¨ LLM usage (optional)

The backend exposes `POST /api/llm/quote/` that turns structured inputs (market signals, events, etc.) into **explanatory copy** (why a price makes sense).

* Default model: **OpenAI `gpt-4o-mini`** (configurable).
* Provide `OPENAI_API_KEY` and (optionally) `LLM_MODEL` in your environment.

> Recommendations themselves are **not** generated by the LLM; it‚Äôs used for human-readable **explanations** only.

## üöÄ Quickstart

### Using Docker (recommended)

```bash
# 1) copy env templates and set secrets
cp .env.example .env           # set values inside
cp frontend/.env.example frontend/.env

# 2) build & run
docker compose up --build

# Backend: http://localhost/
# Frontend: http://localhost/ (served by the frontend container)
```

### Bare-metal (dev)

**Backend**

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r backend/requirements.txt
export DJANGO_SETTINGS_MODULE=config.settings
export SECRET_KEY=dev
export DEBUG=1
export DATABASE_URL=sqlite:///db.sqlite3
# Celery (optional for background runs)
export CELERY_BROKER_URL=redis://localhost:6379/0

python backend/manage.py migrate
python backend/manage.py runserver 0.0.0.0:8000
# (optional) Celery worker:
# celery -A config worker -l info
```

**Frontend**

```bash
cd frontend
npm ci
# point the UI to your API:
# echo 'VITE_API_BASE=/api' > .env.local
npm run dev
```

## üîå API Cheatsheet

```bash
# List listings
curl -s http://localhost/api/listings/ | jq .

# One listing
curl -s http://localhost/api/listings/<LISTING_ID>/ | jq .

# Recommendations for a window (inclusive). 
# If any days are missing, the API computes only that window for that listing.
FROM=2025-12-01
TO=2025-12-18
curl -s "http://localhost/api/listings/<LISTING_ID>/recommendations/?from=$FROM&to=$TO" | jq .

# Optional: LLM explanation
curl -s -X POST http://localhost/api/llm/quote/ \
  -H 'Content-Type: application/json' \
  -d '{"city":"Chennai","date":"2025-12-05","price":3500,"signals":{"occupancy":78,"event_score":1}}' | jq .
```

## ‚è±Ô∏è Scheduled jobs

* `generate_recommendations(days_ahead=30)` ‚Äî iterates active listings and stores recommendations for the next 30 days (idempotent upserts).
  Trigger via Celery beat / cron, e.g., daily at 03:00.

* `generate_recommendations_for_listing(listing_id, from, to, replace=True)` ‚Äî used by the on-demand API to compute a custom window synchronously.

## üñ•Ô∏è Frontend overview

* **Dashboard** ‚Äî hero section, metrics tiles (total listings, cities, rooms median), search, animated listing cards, footer.
* **Listing detail** ‚Äî two calendars; ‚Äúto‚Äù starts **after** ‚Äúfrom‚Äù; chart updates **only** on button press (‚ÄúGet live recommendation‚Äù); loading overlay while fetching.
* **Compare** ‚Äî multi-select with badge chips, large overlay chart, plus **individual mini-charts** below; hides charts if no future data; polished dropdown UI.
* **Doc** ‚Äî in-app documentation with staggered fade-in sections on scroll.

## üîê Configuration

Environment flags you‚Äôll likely set:

| Var                 | Example                | Purpose                  |
| ------------------- | ---------------------- | ------------------------ |
| `SECRET_KEY`        | `change-me`            | Django secret            |
| `DEBUG`             | `0/1`                  | Dev vs prod              |
| `DATABASE_URL`      | `postgres://...`       | DB connection            |
| `CELERY_BROKER_URL` | `redis://redis:6379/0` | Celery broker            |
| `OPENAI_API_KEY`    | `sk-...`               | LLM client               |
| `LLM_MODEL`         | `gpt-4o-mini`          | LLM model name           |
| `VITE_API_BASE`     | `/api`                 | Frontend ‚Üí API base path |

## üß™ Test data (optional snippet)

Inside `manage.py shell` you can seed quick market data:

```py
from datetime import date, timedelta
from decimal import Decimal
from apps.listings.models import Listing, MarketSample, FeaturesDaily

lid = str(Listing.objects.first().id)
listing = Listing.objects.get(id=lid)
start = date(2025,12,1); end = date(2025,12,18)
d = start
while d <= end:
    MarketSample.objects.update_or_create(
        city=listing.city, dt=d,
        defaults={'price': Decimal('180.0') + Decimal(str((d-start).days*15)),
                  'occupancy': 60 + ((d-start).days % 20)}
    )
    FeaturesDaily.objects.update_or_create(
        city=listing.city, dt=d,
        defaults={'event_score': ((d-start).days % 6)}
    )
    d += timedelta(days=1)
```

## üì¶ Production notes

* Serve static files via `collectstatic` (e.g., WhiteNoise or CDN).
* Use Postgres + Redis/RabbitMQ.
* Run `gunicorn` (or similar) behind Nginx; run at least one Celery worker + beat.
* Lock dependencies (`requirements.txt`, `package-lock.json`) and keep secrets in your env or a secret manager.

## üìù License

MIT ‚Äî see `LICENSE`.

--
